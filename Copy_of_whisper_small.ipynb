{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansh-pachauri/GenAI-project-on-collab/blob/main/Copy_of_whisper_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -q langchain-community faiss-cpu langchain-google-genai\n",
        "from datasets import load_dataset\n",
        "!pip install torch torchaudio torchcodec"
      ],
      "metadata": {
        "id": "WHo0EWotj8fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/openai/whisper-small\n",
        "\n",
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/openai/whisper-small)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè"
      ],
      "metadata": {
        "id": "qB4ns2Zdj8fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "t3_cSYEnj8fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "id": "4_2SVcLpj8fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Audio\n",
        "import librosa"
      ],
      "metadata": {
        "id": "KoZ-c_Jprmzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
      ],
      "metadata": {
        "id": "Cphk2QqfmMZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.cast_column(\"audio\", Audio(decode=False))"
      ],
      "metadata": {
        "id": "PDMeGH3XrYA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ds[\"audio\"]"
      ],
      "metadata": {
        "id": "hQGWSUowmNen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "id": "yDQ4tcZ_s6-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptions = []\n",
        "for i in range(2):\n",
        "    sample = ds[i][\"audio\"]\n",
        "    audio_bytes = sample[\"bytes\"]\n",
        "\n",
        "    # Save the audio to a temporary file\n",
        "    with open(f\"temp_{i}.flac\", \"wb\") as f:\n",
        "        f.write(audio_bytes)\n"
      ],
      "metadata": {
        "id": "PvsUrW5rtN29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array, sr = librosa.load(f\"temp_{i}.flac\", sr=16000)\n",
        "print(array.shape, sr)"
      ],
      "metadata": {
        "id": "7SJpKUAKnzk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and transcribe\n",
        "input_features = processor(array, sampling_rate=sr, return_tensors=\"pt\").input_features"
      ],
      "metadata": {
        "id": "oQnttcy2sI5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = model.generate(input_features)"
      ],
      "metadata": {
        "id": "YBz9HOjPt0oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "transcriptions.append(transcription[0]) # Append the first element as batch_decode returns a list\n",
        "\n",
        "print(transcriptions)"
      ],
      "metadata": {
        "id": "vc5Lo4iGt3QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46CQOF4zt8pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48b497d5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}